<!doctype html>
<html lang="en-us">
  <head>
    <title> // My New Hugo Site</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.78.2" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="John Doe" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://timingf.github.io/css/main.min.88e7083eff65effb7485b6e6f38d10afbec25093a6fac42d734ce9024d3defbd.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="机器视觉算法 [TOC]
图像采集一章讲述了将一张图像传送到计算机这一过程中所需的各种硬件部件。例如：为了突出感兴趣的物体时，光源是至关重要的；为了在恰当时刻正确曝光来拍摄一幅图像时，带有外触发功能的图像卡和摄像机就是解决问题的关键；为了获取清晰且没有畸变的图像，镜头就变得很重要。但设备并不会真正去“看”，并不能提取我们感兴趣的信息。就如人的眼睛仅仅只是一个传感器，没有大脑的协助我们仍然处理不了所看到的信息。因此在传感器将图像数据传送到计算机后，对这些图像数据传送到计算机后，对这些图像数据的处理才是机器视觉过程的真正关键。
1.数据结构 本节介绍图像、区域和亚像素轮廓的数据结构。
1.1. 图像 机器视觉里，图像是基本的数据结构，它所包含的数据通常是由图像采集设备传送到计算机内存中的。一个像素能被看成对能量的采样结果，此能量是在曝光过程中传感器 上一个感光单元所累积得到的，它积累了在传感器光谱响应范围内的所有光能。传感器的光谱响应通常包括全部可见光谱和部分近红外光谱。因此，黑白摄像机会返回每个像素所对应的一个能量的采样结果，这些结果就组成了一副单通道灰度值图像。而对RGB彩色摄像机，它将返回每个像素所对应的三个采样结果，也就是一幅三通道图像。再还有遥感图像，图像的每个像素对应非常多的能量采样结果，这样做的目的是对光谱进行更细致的采样，所以每个像素对应更多个能量样本也是可以的。例如，HYDICE传感器的每个像素可以采集210个光谱采样结果。所以，为了处理所有可能的应用，图像可以被视为由一组任意多的通道组成的。很直观地，图像通道可以被简单地看作是一个二维数组，这也是程序设计语言中表示图像时所使用的数据结构。因此在像素（r, c）处的灰度值可以被解释为矩阵： $$ g = f_{r,c} $$ 中的一个元素。使用更正规的描述方式，视某个宽度为 **W** ，高度为 **h** 的图像通道 **f** 为一个函数，该函数表述从离散二维平面的一个矩形子集 $$ R={0,&hellip;,h-1}*{0,&hellip;,w-1},R {\subset} Z^{2} (Z^{2}为离散二维平面) $$ 到某一个实数的关系，像素位置是（r,c）处的灰度值 **g** ，定义为 **g = f(r,c)**。
图像采集设备不但在空间上把图像离散化，同事也会把灰度值离散化到某个固定的 灰度级范围内。多数情况下，灰度值被离散化为8位（一个字节），即所有可能的灰度值所组成的集合是 $$ 2^{8}=256, 即G_{8}={0,&hellip;,255} $$ 有些情况下则需要使用更高的位深。自此**我们已视一幅图像为一个在空间上采样的函数**，如此处理是因为我们就是以这种方式从图像采集设备获取图像的。
1.2. 区域 机器视觉的任务之一就是识别图像中包含某些特性的区域(感兴趣区域ROI)，比如执行一个阈值分割处理（见1.4节）。因此我们还需要一种数据结构，它可以表示一幅图像中一个任意的像素子集。故而，我们把区域定义为离散平面的一个任意子集: $$ R {\subset}Z^{2} $$ {r} 对任意图像，可以用一个包含该图像所有像素点的矩形感兴趣区域来表示该幅图像。我们默认每幅图像都有一个相关的感兴趣区域存在，这个感兴趣区域用 R 来表示。很多时候需要描述一幅图像上多个物体，它们可以由区域的集合来简单地表示。但现在我们还不清楚最好的表示区域的方法。数学上，我们能把区域描述成集合。另一种等价定义将使用区域的特征函数： $$ \begin{equation} {\chi}_{R}{(r,c)}= \begin{cases} 1&amp; , \text{(r,c)} {\in} R\
0&amp; ,\text{(r,c)}{\notin}R \end{cases} \end{equation} $$ 这个定义引入了二值图像来描述区域。一个二值图像用灰度值0表示不在区域内的点，用1（或其他非0的数）表示被包含在区域内的点。同样的我们可以将图像中多个目标物体描绘成多个标记图像，图像中像素灰度值表示此像素属于哪个区域，大于0的标记被用来表示不同区域，0为不被包含的点。
二值图像的弊端：（1）必须存储区域外的点，效率不高； （2）二值图像不易向负坐标区域保存扩展； （3）用标记图像表示多个区域时无法描述交叠区域。"/>

    <meta property="og:title" content="" />
<meta property="og:description" content="机器视觉算法 [TOC]
图像采集一章讲述了将一张图像传送到计算机这一过程中所需的各种硬件部件。例如：为了突出感兴趣的物体时，光源是至关重要的；为了在恰当时刻正确曝光来拍摄一幅图像时，带有外触发功能的图像卡和摄像机就是解决问题的关键；为了获取清晰且没有畸变的图像，镜头就变得很重要。但设备并不会真正去“看”，并不能提取我们感兴趣的信息。就如人的眼睛仅仅只是一个传感器，没有大脑的协助我们仍然处理不了所看到的信息。因此在传感器将图像数据传送到计算机后，对这些图像数据传送到计算机后，对这些图像数据的处理才是机器视觉过程的真正关键。
1.数据结构 本节介绍图像、区域和亚像素轮廓的数据结构。
1.1. 图像 机器视觉里，图像是基本的数据结构，它所包含的数据通常是由图像采集设备传送到计算机内存中的。一个像素能被看成对能量的采样结果，此能量是在曝光过程中传感器 上一个感光单元所累积得到的，它积累了在传感器光谱响应范围内的所有光能。传感器的光谱响应通常包括全部可见光谱和部分近红外光谱。因此，黑白摄像机会返回每个像素所对应的一个能量的采样结果，这些结果就组成了一副单通道灰度值图像。而对RGB彩色摄像机，它将返回每个像素所对应的三个采样结果，也就是一幅三通道图像。再还有遥感图像，图像的每个像素对应非常多的能量采样结果，这样做的目的是对光谱进行更细致的采样，所以每个像素对应更多个能量样本也是可以的。例如，HYDICE传感器的每个像素可以采集210个光谱采样结果。所以，为了处理所有可能的应用，图像可以被视为由一组任意多的通道组成的。很直观地，图像通道可以被简单地看作是一个二维数组，这也是程序设计语言中表示图像时所使用的数据结构。因此在像素（r, c）处的灰度值可以被解释为矩阵： $$ g = f_{r,c} $$ 中的一个元素。使用更正规的描述方式，视某个宽度为 **W** ，高度为 **h** 的图像通道 **f** 为一个函数，该函数表述从离散二维平面的一个矩形子集 $$ R={0,&hellip;,h-1}*{0,&hellip;,w-1},R {\subset} Z^{2} (Z^{2}为离散二维平面) $$ 到某一个实数的关系，像素位置是（r,c）处的灰度值 **g** ，定义为 **g = f(r,c)**。
图像采集设备不但在空间上把图像离散化，同事也会把灰度值离散化到某个固定的 灰度级范围内。多数情况下，灰度值被离散化为8位（一个字节），即所有可能的灰度值所组成的集合是 $$ 2^{8}=256, 即G_{8}={0,&hellip;,255} $$ 有些情况下则需要使用更高的位深。自此**我们已视一幅图像为一个在空间上采样的函数**，如此处理是因为我们就是以这种方式从图像采集设备获取图像的。
1.2. 区域 机器视觉的任务之一就是识别图像中包含某些特性的区域(感兴趣区域ROI)，比如执行一个阈值分割处理（见1.4节）。因此我们还需要一种数据结构，它可以表示一幅图像中一个任意的像素子集。故而，我们把区域定义为离散平面的一个任意子集: $$ R {\subset}Z^{2} $$ {r} 对任意图像，可以用一个包含该图像所有像素点的矩形感兴趣区域来表示该幅图像。我们默认每幅图像都有一个相关的感兴趣区域存在，这个感兴趣区域用 R 来表示。很多时候需要描述一幅图像上多个物体，它们可以由区域的集合来简单地表示。但现在我们还不清楚最好的表示区域的方法。数学上，我们能把区域描述成集合。另一种等价定义将使用区域的特征函数： $$ \begin{equation} {\chi}_{R}{(r,c)}= \begin{cases} 1&amp; , \text{(r,c)} {\in} R\
0&amp; ,\text{(r,c)}{\notin}R \end{cases} \end{equation} $$ 这个定义引入了二值图像来描述区域。一个二值图像用灰度值0表示不在区域内的点，用1（或其他非0的数）表示被包含在区域内的点。同样的我们可以将图像中多个目标物体描绘成多个标记图像，图像中像素灰度值表示此像素属于哪个区域，大于0的标记被用来表示不同区域，0为不被包含的点。
二值图像的弊端：（1）必须存储区域外的点，效率不高； （2）二值图像不易向负坐标区域保存扩展； （3）用标记图像表示多个区域时无法描述交叠区域。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://timingf.github.io/%E7%AC%94%E8%AE%B0/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95%E4%B8%8E%E5%BA%94%E7%94%A8/%E6%9C%BA%E5%99%A8%E8%A7%86%E8%A7%89%E7%AE%97%E6%B3%95/" />



  </head>
  <body>
    <header class="app-header">
      <a href="https://timingf.github.io/"><img class="app-header-avatar" src="/avatar.jpg" alt="John Doe" /></a>
      <h1>My New Hugo Site</h1>
      <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nunc vehicula turpis sit amet elit pretium.</p>
      <div class="app-header-social">
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title"></h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Jan 1, 0001
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div>
      </div>
    </header>
    <div class="post-content">
      <h1 id="机器视觉算法">机器视觉算法</h1>
<p>[TOC]</p>
<p>图像采集一章讲述了将一张图像传送到计算机这一过程中所需的各种硬件部件。例如：为了突出感兴趣的物体时，光源是至关重要的；为了在恰当时刻正确曝光来拍摄一幅图像时，带有外触发功能的图像卡和摄像机就是解决问题的关键；为了获取清晰且没有畸变的图像，镜头就变得很重要。但设备并不会真正去“看”，并不能提取我们感兴趣的信息。就如人的眼睛仅仅只是一个传感器，没有大脑的协助我们仍然处理不了所看到的信息。因此在传感器将图像数据传送到计算机后，对这些图像数据传送到计算机后，对这些图像数据的处理才是机器视觉过程的真正关键。</p>
<h2 id="1数据结构">1.数据结构</h2>
<p>本节介绍图像、区域和亚像素轮廓的数据结构。</p>
<h3 id="11-图像">1.1. 图像</h3>
<p>机器视觉里，图像是基本的数据结构，它所包含的数据通常是由图像采集设备传送到计算机内存中的。一个像素能被看成对能量的采样结果，此能量是在曝光过程中传感器 上一个感光单元所累积得到的，它积累了在传感器光谱响应范围内的所有光能。传感器的光谱响应通常包括全部可见光谱和部分近红外光谱。因此，<!-- raw HTML omitted -->黑白摄像机会返回每个像素所对应的一个能量的采样结果，这些结果就组成了一副单通道灰度值图像。而对RGB彩色摄像机，它将返回每个像素所对应的三个采样结果，也就是一幅三通道图像。<!-- raw HTML omitted -->再还有遥感图像，图像的每个像素对应非常多的能量采样结果，这样做的目的是对光谱进行更细致的采样，所以每个像素对应更多个能量样本也是可以的。例如，HYDICE传感器的每个像素可以采集210个光谱采样结果。所以，<!-- raw HTML omitted -->为了处理所有可能的应用，图像可以被视为由一组任意多的通道组成的。<!-- raw HTML omitted --></p>
<p>很直观地，<strong>图像通道可以被简单地看作是一个二维数组</strong>，这也是程序设计语言中表示图像时所使用的数据结构。因此在像素（r, c）处的灰度值可以被解释为矩阵： 
$$
g = f_{r,c}
$$
中的一个元素。使用更正规的描述方式，视某个宽度为 **W** ，高度为 **h** 的图像通道 **f** 为一个函数，该函数表述从离散二维平面的一个矩形子集
$$
R={0,&hellip;,h-1}*{0,&hellip;,w-1},R {\subset} Z^{2} (Z^{2}为离散二维平面)
$$
到某一个实数的关系，像素位置是（r,c）处的灰度值 **g** ，定义为 **g = f(r,c)**。</p>
<p>图像采集设备不但在空间上把图像离散化，同事也会把灰度值离散化到某个固定的 灰度级范围内。多数情况下，灰度值被离散化为8位（一个字节），即所有可能的灰度值所组成的集合是
$$
2^{8}=256, 即G_{8}={0,&hellip;,255}
$$
有些情况下则需要使用更高的位深。自此**我们已视一幅图像为一个在空间上采样的函数**，如此处理是因为我们就是以这种方式从图像采集设备获取图像的。</p>
<h3 id="12-区域">1.2. 区域</h3>
<p>机器视觉的任务之一就是<!-- raw HTML omitted -->识别图像中包含某些特性的区域<!-- raw HTML omitted --><strong>(感兴趣区域ROI)</strong>，比如执行一个<strong>阈值分割处理</strong>（见1.4节）。<strong>因此我们还需要一种数据结构，它可以表示一幅图像中一个任意的像素子集</strong>。故而，我们把区域定义为离散平面的一个任意子集:
$$
R {\subset}Z^{2}
$$ {r}
对任意图像，可以用一个包含该图像所有像素点的矩形感兴趣区域来表示该幅图像。我们默认每幅图像都有一个相关的感兴趣区域存在，这个感兴趣区域用 <strong>R</strong> 来表示。很多时候<!-- raw HTML omitted -->需要描述一幅图像上多个物体，它们可以由区域的集合来简单地表示。<!-- raw HTML omitted --></p>
<p>但现在我们还不清楚最好的表示区域的方法。数学上，我们能把区域描述成集合。另一种等价定义将使用区域的特征函数：
$$
\begin{equation}
{\chi}_{R}{(r,c)}=
\begin{cases}
1&amp; , \text{(r,c)} {\in} R\<br>
0&amp; ,\text{(r,c)}{\notin}R
\end{cases}
\end{equation}
$$
这个定义引入了二值图像来描述区域。一个二值图像用灰度值0表示不在区域内的点，用1（或其他非0的数）表示被包含在区域内的点。同样的我们可以将图像中多个目标物体描绘成多个标记图像，图像中像素灰度值表示此像素属于哪个区域，大于0的标记被用来表示不同区域，0为不被包含的点。</p>
<p><strong>二值图像的弊端</strong>：（1）必须存储区域外的点，效率不高； （2）二值图像不易向负坐标区域保存扩展；         （3）用标记图像表示多个区域时无法描述交叠区域。</p>
<p>因此需要找到一种通过高效率的方式仅存储区域内所包含的点来表示区域。</p>
<p>表3.1是区域的一个小例子：</p>
<p><img src="..%5Cimages%5C1571573136754.png" alt="1571573136754"></p>
<p>沿水平或垂直方向，行程延伸所覆盖的邻近像素点属于一个区域。如图所示的区域能用四个行程来保存，区域也可以表示为该区域全部行程的一个并集：
$$
R={\bigcup_{i=1}^{n}}  r_i
$$</p>
<p>此处，Ri表示一个行程，也可以表示一个区域。行程存储的顺序是根据其纵坐标和起始横坐标的字典序确定的，这样的排序方式对于算法的执行速度是至关重要的。</p>
<p>上个例子中，若每个像素占一个字节，，采用二值图像来描述区域要占用35个字节，如果每个像素占一位，此区域也需要5个字节（因为每个格子都要存储为数值）。**而采用行程编码时，如果区域的坐标值保存在16位的整数中，只需要24个字节即可（2字节*12个数据）。**虽然没有节省很多空间，但我们注意到使用行程编码时仅仅需要保存区域的边界。而边界上的点的数量与区域面积的平方根成比例。由于二值图像法至少需要保存区域外接矩形内所有像素点，所以使用行程编码相较于二值图像法通常会明显减少存储空间的使用。例如：对于w X h的一个矩形区域，只需要存储h个行程，而二值发需要保存w X h 个像素点（即，w h或(w h/8)个字节）。另外，行程编码仅存储区域内的点，所以无需检查像素是在区域内还是区域外。最后，为了表示多个区域，我们可以使用链表或数组来保存行程编码描述的多个区域，此时由于每个区域的信息是被独立保存和处理的，因此处理交叠区域也没有问题</p>
<h3 id="13-亚像素精度轮廓">1.3. 亚像素精度轮廓</h3>
<p>通常讨论的数据结构都是像素级别的。因为某些应用需要达到比图像分辨率还高的精度，因此从图像中提取亚像素精度数据是很重要的。亚像素数据可以通过亚像素阈值分割或亚像素边缘提取来获得。图 3.1 显示了几个轮廓的例子：</p>
<p><img src="..%5Cimages%5C1571738889178.png" alt="1571738889178"></p>
<p>典型的轮廓提取是基于像素网络的。，轮廓上控制点之间的距离平均约为1个像素。在计算机里，轮廓只是用浮点数表示的横和纵坐标所构成的数组来表示的。闭合轮廓（图1）通常使用同一个坐标来表示轮廓上的第一个点和最后一个点，或使用一个特殊属性来表示。此外，几个轮廓能在一个结合点汇合，如轮廓3、4、5.</p>
<h2 id="2-图像增强">2. 图像增强</h2>
<h3 id="21-灰度值变换">2.1. 灰度值变换</h3>
<p>调整图像灰度值的一个原因是由于<strong>图像对比度太弱</strong>，通过对照光源的调整，整个问题通常只会局部发生，所以，我们也许只需增强局部的对比度。另一个原因是<strong>图像对比度或亮度同最初系统设定时相比已经发生了变化</strong>。比如，在工作一段时间后由于光源的老化而造成图像对比度变弱。灰度值变换可被视为一种点处理。意味着变换后的灰度值$$t_{r,c}$$仅依赖于输入图像上同一个位置上的灰度值$$ g_{r,c}:t_{r,c} = f(g_{r,c}) $$。这里，$$f(g)$$是表示进行灰度值变换的函数。为了提高变换速度，灰度值变换通常通过查找表（$$LUT$$）来进行，即将每个输入灰度值变换后得到的输出值保存在查找表内。如果用$$f_g$$表示$$LUT$$，则$$t_{r,c}=f_{g}[g_{r,c}]$$，此处[ ]表示的是查表操作。</p>
<p>最重要的灰度值变换是灰度值线性比例缩放：$$f(g) = ag + b$$。若值域有范围 G 我们需要保证输出灰度值也在G内。所以我们需要按照下式对输出灰度值进行裁剪和四舍五入处理：
$$
f(g)=min(max({\lfloor}ag {+} b {+} 0.5{\rfloor},0), 2^{b}-1)
$$
当|a|&gt;1时，对比度增加，当|a|&lt;1时，对比度则降低。当a&lt;0时，灰度值反转，b&gt;0时，亮度值增加，b&lt;0时，亮度值降低。图3.2显示印刷电路板局部基础变换：</p>
<p><img src="..%5Cimages%5C1571907128948.png" alt="1571907128948"></p>
<p>参数选择十分麻烦，我们希望能有一种可基于当前图像情况自动确定a和b的方法。一种显而易见的方法是通过设置参数让变换后的图像灰度值覆盖$$G_b$$的最大取值范围。可进行如下操作：用$$g_{min}$$和$$g_{max}$$分别保存当前ROI图像中的最小灰度值和最大灰度值。然后，当$$a=(2^{b}-1)/(g_{max}-g_{min})$$  且$$b=-ag_{min}$$时转换后的输出灰度值可以覆盖$$G_{b}$$的最大取值范围。这种变换可以被理解为灰度值的归一化处理。图3.2（f）给出了结果。但对比度并没有明显改善，这是由于焊锡的镜面反射造成的，这些反光部分已经达到了最高的灰度值，而又因为图像上的暗区域的灰度值也几乎达到了最小的灰度值0，所以，已经没有多少空间来进行对比度的提升处理了。</p>
<p><img src="..%5Cimages%5C1571907744259.png" alt="1571907744259"></p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
